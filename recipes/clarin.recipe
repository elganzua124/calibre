from __future__ import unicode_literals
__license__   = 'GPL v3'
__copyright__ = '2008-2012, Darko Miletic <darko.miletic at gmail.com>'
'''
clarin.com
'''

from calibre.web.feeds.news import BasicNewsRecipe

class Clarin(BasicNewsRecipe):
    title                 = 'Clarín'
    __author__            = 'Darko Miletic'
    description           = 'Clarin.com. Noticias de la Argentina y el mundo. Información actualizada las 24 horas y en español. Informate ya'
    publisher             = 'Grupo Clarin'
    category              = 'news, politics, Argentina'
    oldest_article        = 2
    max_articles_per_feed = 100
    use_embedded_content  = False
    no_stylesheets        = True
    encoding              = 'utf8'
    delay                 = 1
    language              = 'es_AR'
    publication_type      = 'newspaper'
    INDEX                 = 'http://www.clarin.com/politica'
    masthead_url          = 'http://www.clarin.com/static/CLAClarin/images/logo-clarin-print.jpg'
    extra_css             = """
                               body{font-family: Arial,Helvetica,sans-serif}
                               h2{font-family: Georgia,serif; font-size: xx-large}
                               .info,.columnista,.hora{font-size: small}
                            """

    #ignore_duplicate_articles = {'title', 'url'} # mucho redireccionamiento entre clarin.com y clarin.ieco.com

    conversion_options = {
                          'comment'  : description
                        , 'tags'     : category
                        , 'publisher': publisher
                        , 'language' : language
                        }
'''
feeds = [
               (u'Página principal' , u'http://www.clarin.com/rss/')
              ,(u'Política'         , u'http://www.clarin.com/rss/politica/')
              ,(u'Sociedad'         , u'http://www.clarin.com/rss/sociedad/')

              ,(u'Deportes'         , u'http://www.clarin.com/rss/deportes/')
              ,(u'Mundo'            , u'http://www.clarin.com/rss/mundo/')
              ,(u'iEco'             , u'http://www.clarin.com/rss/ieco/') 
              ,(u'ExtraShow'        , u'http://www.clarin.com/rss/extrashow/')
              
              ,(u'Ciudades'         , u'http://www.clarin.com/rss/ciudades/')
              ,(u'Policiales'       , u'http://www.clarin.com/rss/policiales/')
              ,(u'Tecnología'       , u'http://next.clarin.com/rss/')
              ,(u'Rural'            , u'http://www.clarin.com/rss/rural/')
              ,(u'Educación'        , u'http://www.clarin.com/rss/educacion/')
              ,(u'Opinión'          , u'http://www.clarin.com/rss/opinion/')
]
'''

    keep_only_tags    = [
        dict(name='h1'),
        dict(name='div', attrs={'class':'img-box'}),
        dict(name='div', attrs={'class':'nota'}),
        dict(name='div', attrs={'class':'columnista'})
        #,dict(name='article', id={'Aries','Tauro'})

    ]

    #preprocess_regexps = [(re.compile(r'<head>.*?</head>', re.DOTALL), lambda
     #   m:'<head></head>')]

    remove_tags       = [
        dict(name=['meta','base','link','iframe','embed','object'])
    ]
    remove_attributes = ['lang']


    def print_version(self, url):
        return url + '?print=1'

    def parse_index(self):
        soup = self.index_to_soup(self.INDEX)
        col = soup.find(name=['ul'], attrs={'class':'items'})
        current_articles, feeds = [], []
        for tag in col.findAll(name=['li'], attrs={'class':'item'}):
            a = tag.find('a', href=True)
            h3 = tag.find('h3')
            if a is not None:
                title, url = self.tag_to_string(h3), 'http://www.clarin.com' + a['href']
                if title and url:
                    p = tag.find('p')
                    desc = self.tag_to_string(p) if p is not None else ''
                    current_articles.append({'title':title, 'url':url, 'description':desc})
                    self.log('\tArticle:', title, '[%s]' % url)
                    self.log('\t\t', desc)
        if current_articles:
            feeds.append(('Política', current_articles))
        return feeds

http://www.clarin.com/horoscopo.html



    def get_article_url(self, article):
        return article.get('guid',  None)

    def get_cover_url(self):
        cover_url = "http://tapas.clarin.com/tapa/"
        myarray = [time.strftime("%Y"),time.strftime("%m"),time.strftime("%d")]
        for x in range(len(myarray)):
            cover_url = cover_url + myarray[x] + "/"
        cover_url = cover_url + time.strftime("%Y%m%d")+ "_thumb.jpg"
        return cover_url



'''
    def parse_index(self):
        soup = self.index_to_soup(self.INDEX)
        col = soup.find(attrs={'class':'contentColumn singleContent'})
        current_section, current_articles = None, []
        feeds = []
        for tag in col.findAll(name=['h2', 'li'], attrs={'class':['section-header', 'top-item', 'river-item']}):
            if tag.name == 'h2':
                if current_section and current_articles:
                    feeds.append((current_section, current_articles))
                current_section = self.tag_to_string(tag).capitalize()
                current_articles = []
                self.log('Found section:', current_section)
            elif current_section:
                a = tag.find('a', href=True)
                if a is not None:
                    title, url = self.tag_to_string(a), a['href']
                    if title and url:
                        p = tag.find('p', attrs={'class':'river-dek'})
                        desc = self.tag_to_string(p) if p is not None else ''
                        current_articles.append({'title':title, 'url':url, 'description':desc})
                        self.log('\tArticle:', title, '[%s]' % url)
                        self.log('\t\t', desc)
        if current_section and current_articles:
            feeds.append((current_section, current_articles))
        return feeds
'''
